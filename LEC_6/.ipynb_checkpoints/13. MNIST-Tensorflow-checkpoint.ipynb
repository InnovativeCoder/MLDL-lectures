{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) #getting depricated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x12f9bd828>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x12f9bd7b8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x12f9bd470>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.train.labels.shape #images are 28 x 28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape, mnist.test.labels.shape #labels are one_hot that is why they are 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let's plot the image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f695cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_image = mnist.train.images[50]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "first_image = first_image.reshape((28,28)) #images were flattened by default\n",
    "plt.imshow(first_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.30369195  0.02883767 -0.47428226 ..., -1.47021675  0.31341851\n",
      "   1.46269608]\n",
      " [-1.21341753  0.58935678  0.1270628  ...,  0.28019038 -1.92573047\n",
      "  -0.77701652]\n",
      " [-0.8166036   1.23244083  1.41464698 ..., -1.44504046  0.13220797\n",
      "   0.38869116]\n",
      " ..., \n",
      " [ 1.29005814 -1.45907724 -0.29812655 ...,  0.57097876  0.75617617\n",
      "  -2.16167498]\n",
      " [ 0.14252061  0.9454844  -1.06582093 ..., -1.69518256 -1.73992813\n",
      "  -1.1860832 ]\n",
      " [ 0.66275382  1.29749119 -2.2147243  ...,  2.12400746  1.77669978\n",
      "  -0.83294159]]\n"
     ]
    }
   ],
   "source": [
    "#let's see some dummy data for randon_variable\n",
    "with tf.Session() as sess:\n",
    "    print(tf.random_normal([784, 256]).eval()) #random_normal gives random values, also takes shape as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights & biases\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n",
    "n_classes = 10\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])), #784 x 256, randon_normal will give random values\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(784, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(256, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables() #optimzer only works on trainable variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#forward propagation code\n",
    "def forward_propagation(x, weights, biases):\n",
    "    in_layer1 = tf.add(tf.matmul(x, weights['h1']), biases['h1']) #mx + c, all in matrix\n",
    "    out_layer1 = tf.nn.relu(in_layer1) #same as we applied sigmoid\n",
    "    \n",
    "    in_layer2 = tf.add(tf.matmul(out_layer1, weights['h2']), biases['h2'])\n",
    "    out_layer2 = tf.nn.relu(in_layer2)\n",
    "    \n",
    "    output = tf.add(tf.matmul(out_layer2, weights['out']), biases['out'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#calling forward propagation\n",
    "x = tf.placeholder(\"float\", [None, n_input]) #None as we are not sure about the no. images, sometimes training \n",
    "                                        #some time testing\n",
    "y = tf.placeholder(tf.int32, [None, n_classes]) #classes\n",
    "pred = forward_propagation(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1) #argmax for index of max value, for this case 1 in one hot encode , parameter 1 tells the axis\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum() #getting around 5-10% correct without optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Optimizng our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-32-f4a9e59242c0>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels = y)) #using cross entropy cost , the formual for cost we saw in logistic regression\n",
    "#taking mean of cost as we don't want 10,000 size array, taking mean of all the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "optimize = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664.42\n",
      "1059.85\n",
      "682.018\n",
      "562.575\n",
      "427.207\n",
      "310.706\n",
      "248.721\n",
      "198.521\n",
      "161.332\n",
      "136.914\n",
      "123.477\n",
      "118.373\n",
      "114.615\n",
      "107.768\n",
      "98.1396\n",
      "88.7831\n",
      "81.8922\n",
      "77.5254\n",
      "74.2866\n",
      "70.932\n",
      "66.9709\n",
      "62.6892\n",
      "58.5972\n",
      "54.9741\n",
      "51.804\n"
     ]
    }
   ],
   "source": [
    "for i in range(25):\n",
    "    c, _ = sess.run([cost,optimize], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels}) #optimizing and calc. cost, each run gives low cost\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8841"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1) #argmax for index of max value, for this case 1 in one hot encode , parameter 1 tells the axis\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels)\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25198.8123264\n",
      "4930.7962018\n",
      "2679.94222737\n",
      "1921.91261989\n",
      "1542.48444042\n",
      "1212.79884847\n",
      "1047.42894068\n",
      "1088.13028917\n",
      "932.061613186\n",
      "759.60149467\n",
      "684.364682841\n",
      "517.65975991\n",
      "694.464574642\n",
      "581.080858885\n",
      "458.551185259\n",
      "425.184032181\n",
      "408.098744242\n",
      "363.562671582\n",
      "360.545342507\n",
      "243.874328529\n",
      "296.146465148\n",
      "256.883270334\n",
      "244.686703605\n",
      "219.031780455\n",
      "189.218703413\n"
     ]
    }
   ],
   "source": [
    "#Batch gradient descent\n",
    "batch_size = 100\n",
    "for i in range(25):\n",
    "    num_batches = int(mnist.train.num_examples/batch_size)\n",
    "    total_cost = 0\n",
    "    for j in range(num_batches):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size) #by default provides next batch\n",
    "        c, _ = sess.run([cost,optimize], feed_dict={x:batch_x , y:batch_y}) #optimizing and calc. cost, each run gives low cost\n",
    "        total_cost += c\n",
    "    print(total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9589"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = tf.argmax(pred, 1) #argmax for index of max value, for this case 1 in one hot encode , parameter 1 tells the axis\n",
    "correct_labels = tf.argmax(y, 1)\n",
    "correct_predictions = tf.equal(predictions, correct_labels) #tells us where the value are equal\n",
    "predictions,correct_predictions  = sess.run([predictions, correct_predictions], feed_dict={x:mnist.test.images,\n",
    "                                              y:mnist.test.labels})\n",
    "correct_predictions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
